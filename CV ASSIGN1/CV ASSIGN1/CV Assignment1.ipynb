{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ded3177d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\n"
     ]
    }
   ],
   "source": [
    "!pip install depthai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d6ac8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bedb6c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import depthai as dai\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73ee019",
   "metadata": {},
   "source": [
    "#### 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf1ac51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3n/gb1_zg1s1qxdh0jcmf5zwl600000gn/T/ipykernel_12841/1247709747.py:19: DeprecationWarning: LEFT is deprecated, use CAM_B or address camera by name  instead.\n",
      "  left.setBoardSocket(dai.CameraBoardSocket.LEFT)\n",
      "/var/folders/3n/gb1_zg1s1qxdh0jcmf5zwl600000gn/T/ipykernel_12841/1247709747.py:22: DeprecationWarning: RIGHT is deprecated, use CAM_C or address camera by name  instead.\n",
      "  right.setBoardSocket(dai.CameraBoardSocket.RIGHT)\n"
     ]
    }
   ],
   "source": [
    "# Closer-in minimum depth, disparity range is doubled (from 95 to 190):\n",
    "extended_disp = False\n",
    "# Better accuracy for longer distance, fractional disparity 32-levels:\n",
    "sub_pixelel = False\n",
    "# Better handling for occlusions:\n",
    "lr_check = True\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = dai.Pipeline()\n",
    "\n",
    "# camera configurations\n",
    "camera_rgb = pipeline.create(dai.node.ColorCamera)\n",
    "camera_rgb.setResolution(dai.ColorCameraProperties.SensorResolution.THE_1080_P)\n",
    "xout_rgb = pipeline.createXLinkOut()\n",
    "xout_rgb.setStreamName(\"rgb\")\n",
    "camera_rgb.video.link(xout_rgb.input)\n",
    "left = pipeline.createMonoCamera()\n",
    "left.setResolution(dai.MonoCameraProperties.SensorResolution.THE_400_P)\n",
    "left.setBoardSocket(dai.CameraBoardSocket.LEFT)\n",
    "right = pipeline.createMonoCamera()\n",
    "right.setResolution(dai.MonoCameraProperties.SensorResolution.THE_400_P)\n",
    "right.setBoardSocket(dai.CameraBoardSocket.RIGHT)\n",
    "depth = pipeline.createStereoDepth()\n",
    "left.out.link(depth.left)\n",
    "right.out.link(depth.right)\n",
    "xout = pipeline.createXLinkOut()\n",
    "xout.setStreamName(\"disparity\")\n",
    "depth.disparity.link(xout.input)\n",
    "\n",
    "prev_frame_time = 0\n",
    "new_frame_time = 0\n",
    "DIM = (720, 480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "862bfb35",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No available devices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/sravyakunduru/Desktop/cv-nikki/CV ASSIGN1/CV Assignment1.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sravyakunduru/Desktop/cv-nikki/CV%20ASSIGN1/CV%20Assignment1.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m dai\u001b[39m.\u001b[39;49mDevice(pipeline) \u001b[39mas\u001b[39;00m device:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sravyakunduru/Desktop/cv-nikki/CV%20ASSIGN1/CV%20Assignment1.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sravyakunduru/Desktop/cv-nikki/CV%20ASSIGN1/CV%20Assignment1.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m# Output queue will be used to get the disparity frames from the outputs defined above\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sravyakunduru/Desktop/cv-nikki/CV%20ASSIGN1/CV%20Assignment1.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     q \u001b[39m=\u001b[39m device\u001b[39m.\u001b[39mgetOutputQueue(name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdisparity\u001b[39m\u001b[39m\"\u001b[39m, maxSize\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, blocking\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sravyakunduru/Desktop/cv-nikki/CV%20ASSIGN1/CV%20Assignment1.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     q_rgb \u001b[39m=\u001b[39m device\u001b[39m.\u001b[39mgetOutputQueue(name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrgb\u001b[39m\u001b[39m\"\u001b[39m, maxSize\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, blocking\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No available devices"
     ]
    }
   ],
   "source": [
    "with dai.Device(pipeline) as device:\n",
    "\n",
    "    # Output queue will be used to get the disparity frames from the outputs defined above\n",
    "    q = device.getOutputQueue(name=\"disparity\", maxSize=4, blocking=False)\n",
    "    q_rgb = device.getOutputQueue(name=\"rgb\", maxSize=4, blocking=False)\n",
    "    while True:\n",
    "\n",
    "        new_frame_time = time.time()\n",
    "\n",
    "        fps = 1 / (new_frame_time - prev_frame_time)\n",
    "        prev_frame_time = new_frame_time\n",
    "        fps = int(fps)\n",
    "\n",
    "        in_rgb = q_rgb.get()\n",
    "\n",
    "        in_disparity = q.get()  # blocking call, will wait until a new data has arrived\n",
    "        frame = in_disparity.getFrame()\n",
    "\n",
    "        # Normalization for better visualization\n",
    "        frame = (frame * (255 / depth.initialConfig.getMaxDisparity())).astype(np.uint8)\n",
    "\n",
    "        frame_rgb = cv.resize(in_rgb.getCvFrame(), DIM, interpolation=cv.INTER_AREA)\n",
    "\n",
    "        cv.imshow(\"rgb\", frame_rgb)\n",
    "        cv.imshow(\"disparity\", frame)\n",
    "\n",
    "        print(\"FPS: \", fps)\n",
    "        if cv.waitKey(1) == ord('q'):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4aa6d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import time\n",
    "from pathlib import Path\n",
    "import depthai as dai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55507833",
   "metadata": {},
   "source": [
    "##### 1, 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52b8d8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    function to capture 10 images from mentioned source \n",
    "    - source can be RIGHT or LEFT monochrome camera of OAK D LITE\n",
    "    - images captured at 1000 sec interval\n",
    "    \n",
    "    params : \n",
    "    \n",
    "        src = {'right' || 'left'} (default : right)\n",
    "        delay = {delay in ms} (default : 1000)\n",
    "'''\n",
    "\n",
    "def captureImages(src='right', delay=1000):\n",
    "    if src != 'right' and src != 'left': \n",
    "        print(\"ENTER CORRECT PARAMS!\")\n",
    "        print(\"accepted params: {left, right} \")\n",
    "        print(f\"entered src:{src}\")\n",
    "        return;\n",
    "    \n",
    "    # Start defining a pipeline\n",
    "    pipeline = dai.Pipeline()\n",
    "\n",
    "    # Define a source - mono (grayscale) camera\n",
    "    # LEFT or RIGHT    \n",
    "    \n",
    "    cam = pipeline.createMonoCamera()\n",
    "    \n",
    "    if src == 'right' :\n",
    "        cam.setBoardSocket(dai.CameraBoardSocket.RIGHT)\n",
    "    else :\n",
    "        cam.setBoardSocket(dai.CameraBoardSocket.LEFT)\n",
    "\n",
    "    cam.setResolution(dai.MonoCameraProperties.SensorResolution.THE_480_P)\n",
    "\n",
    "    # Create output\n",
    "    xout = pipeline.createXLinkOut()\n",
    "    xout.setStreamName(src)\n",
    "    cam.out.link(xout.input)\n",
    "\n",
    "    # Connect and start the pipeline\n",
    "    with dai.Device(pipeline,usb2Mode=True) as device:\n",
    "\n",
    "        # Output queue will be used to get the grayscale frames from the output defined above\n",
    "        q = device.getOutputQueue(name=src, maxSize=4, blocking=False)\n",
    "\n",
    "        # Make sure the destination path is present before starting to store the examples\n",
    "        Path(f\"images/{src}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for i in range(10):\n",
    "            # Blocking call, will wait until a new data has arrived\n",
    "            inSrc = q.get()  \n",
    "            # Data is originally represented as a flat 1D array, it needs to be converted into HxW form\n",
    "            frame = inSrc.getCvFrame()\n",
    "            # Frame is transformed and ready to be shown\n",
    "            cv.imshow(src, frame)\n",
    "\n",
    "            cv.imwrite(f\"images/{src}/{int(time.time() * 10000)}.png\", frame)\n",
    "            cv.waitKey(delay)  \n",
    "\n",
    "            cv.destroyAllWindows()            \n",
    "\n",
    "\n",
    "def captureColorImages(delay=1000):\n",
    "    \n",
    "    # Start defining a pipeline\n",
    "    pipeline = dai.Pipeline()\n",
    "\n",
    "    # Define a source - color camera\n",
    "    \n",
    "    cam = pipeline.createColorCamera()\n",
    "    cam.setResolution(dai.ColorCameraProperties.SensorResolution.THE_1080_P)\n",
    "\n",
    "    # Create RGB output\n",
    "    xout = pipeline.createXLinkOut()\n",
    "    xout.setStreamName(\"rgb\")\n",
    "    cam.video.link(xout.input)\n",
    "\n",
    "    # Connect and start the pipeline\n",
    "    with dai.Device(pipeline,usb2Mode=True) as device:\n",
    "\n",
    "        # Output queue will be used to get the color frames from the output defined above\n",
    "        q = device.getOutputQueue(name=\"rgb\", maxSize=4, blocking=False)\n",
    "\n",
    "        # Make sure the destination path is present before starting to store the examples\n",
    "        Path(f\"images/rgb\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for i in range(10):\n",
    "            # Blocking call, will wait until a new data has arrived\n",
    "            inSrc = q.get()  \n",
    "            # Data is originally represented as a flat 1D array, it needs to be converted into HxW form\n",
    "            frame = inSrc.getCvFrame()\n",
    "            # Frame is transformed and ready to be shown\n",
    "            imS = cv.resize(frame, (960, 540)) # Resize image\n",
    "            cv.imshow(\"rgb\", imS)   \n",
    "#             cv.imshow(\"rgb\", frame)\n",
    "\n",
    "            cv.imwrite(f\"images/rgb/{int(time.time() * 10000)}.png\", frame)\n",
    "            cv.waitKey(delay)  \n",
    "\n",
    "            cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "342bd27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    function to find corners, caliberate and store \n",
    "    camera matrix and distortion vector from mentioned source \n",
    "    - source can be RIGHT or LEFT monochrome camera or COLOR camera \n",
    "    of OAK D LITE\n",
    "    \n",
    "    params : \n",
    "        images = {array of image paths}\n",
    "        src = source file {'right' || 'left' || 'rgb'} \n",
    "'''\n",
    "\n",
    "def caliberate(images, src):\n",
    "    if src != 'right' and src != 'left' and src != 'rgb': \n",
    "        print(\"ENTER CORRECT PARAMS!\")\n",
    "        print(\"accepted params: {left, right, rgb} \")\n",
    "        print(f\"entered src:{src}\")\n",
    "        return;\n",
    "\n",
    "    \n",
    "    # termination criteria\n",
    "    criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((6*9,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d point in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    notFound = []\n",
    "\n",
    "#     img_size = () # will be using this for caliberation\n",
    "\n",
    "    for fname in images:\n",
    "        img = cv.imread(fname)\n",
    "        gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "        \n",
    "#         img_size = gray.shape[::-1]\n",
    "    \n",
    "        cv.imshow('gray', img)        \n",
    "        cv.waitKey(1000)\n",
    "        cv.destroyAllWindows()\n",
    "\n",
    "        # Finding chess board corners\n",
    "        ret, corners = cv.findChessboardCorners(gray, (9,6), None)\n",
    "\n",
    "        # If found, add object points, image points (after refining them)\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            corners2 = cv.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            cv.drawChessboardCorners(img, (9,6),corners2, ret)\n",
    "            cv.imshow('img', img)\n",
    "\n",
    "            # Saving diplayed corners for future references\n",
    "            cv.imwrite(f\"{fname.split('.')[0]}_corners.png\", img)\n",
    "            cv.waitKey(1000)\n",
    "            cv.destroyAllWindows()\n",
    "        else :\n",
    "            # if corners not found, storing it into a list\n",
    "\n",
    "            notFound.append(fname)\n",
    "            print(f\"corners not found for {fname}\")\n",
    "\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "    # removing the pictures whose corners werent found\n",
    "    # from the main image list\n",
    "    for i in notFound:\n",
    "        images.remove(i)\n",
    "\n",
    "    # calibration\n",
    "    ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "        \n",
    "    for fname in images:\n",
    "        img = cv.imread(fname)\n",
    "        h,  w = img.shape[:2]\n",
    "        newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "\n",
    "        # undistort\n",
    "        dst = cv.undistort(img, mtx, dist, None, newcameramtx)\n",
    "\n",
    "        # crop the image\n",
    "        x, y, w, h = roi\n",
    "        dst = dst[y:y+h, x:x+w]\n",
    "        \n",
    "        # save new image into file\n",
    "        cv.imwrite(f\"{fname.split('.')[0]}_result.png\", dst)\n",
    "        \n",
    "        \n",
    "    # we will be storing the camera matrix and \n",
    "    # distortion coefficients for future uses\n",
    "\n",
    "    print(\"Saving camera matrix...\")\n",
    "    camera_matrix = np.matrix(mtx)\n",
    "    with open(f\"images/{src}/camera_matrix.txt\",'wb') as f:\n",
    "        for line in camera_matrix:\n",
    "            np.savetxt(f, line, fmt='%.5f')\n",
    "            \n",
    "    print(\"Saving distortion vector...\")\n",
    "    distortion_vector = np.matrix(dist)\n",
    "    with open(f\"images/{src}/distortion_matrix.txt\",'wb') as f:\n",
    "        for line in distortion_vector:\n",
    "            np.savetxt(f, line, fmt='%.5f')\n",
    "            \n",
    "    \n",
    "    print(\"Saving rotational vectors ...\")\n",
    "    rotation_vectors = np.array(rvecs)\n",
    "    with open(f\"images/{src}/rotat_vector.txt\",'wb') as f:\n",
    "        for vector in rotation_vectors:\n",
    "            vector = np.reshape(vector, (1,3))\n",
    "            np.savetxt(f, vector, fmt='%.5f')\n",
    "            \n",
    "    print(\"Saving translation vectors...\")\n",
    "    translation_vectors = np.array(tvecs)\n",
    "    with open(f\"images/{src}/trans_vector.txt\",'wb') as f:\n",
    "        for vector in translation_vectors:\n",
    "            vector = np.reshape(vector, (1,3))\n",
    "            np.savetxt(f, vector, fmt='%.5f')\n",
    "            \n",
    "    print('Done!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d20f8919",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'captureImages' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/sravyakunduru/Desktop/cv-nikki/CV ASSIGN1/CV Assignment1.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sravyakunduru/Desktop/cv-nikki/CV%20ASSIGN1/CV%20Assignment1.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sravyakunduru/Desktop/cv-nikki/CV%20ASSIGN1/CV%20Assignment1.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m    calling function to capture images\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sravyakunduru/Desktop/cv-nikki/CV%20ASSIGN1/CV%20Assignment1.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sravyakunduru/Desktop/cv-nikki/CV%20ASSIGN1/CV%20Assignment1.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m    \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sravyakunduru/Desktop/cv-nikki/CV%20ASSIGN1/CV%20Assignment1.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sravyakunduru/Desktop/cv-nikki/CV%20ASSIGN1/CV%20Assignment1.ipynb#X13sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# capturing images using right monochrome camera\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sravyakunduru/Desktop/cv-nikki/CV%20ASSIGN1/CV%20Assignment1.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m captureImages(\u001b[39m'\u001b[39m\u001b[39mright\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sravyakunduru/Desktop/cv-nikki/CV%20ASSIGN1/CV%20Assignment1.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# capturing images using left monochrome camera\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sravyakunduru/Desktop/cv-nikki/CV%20ASSIGN1/CV%20Assignment1.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m captureImages(\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'captureImages' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    calling function to capture images\n",
    "    \n",
    "    I have used the previously declared function to \n",
    "    capture 10 images of a chessboard \n",
    "    \n",
    "    these images are then used to caliberate the camera\n",
    "    i used a 8x6 chess board for caliberations purposes\n",
    "    \n",
    "'''\n",
    "\n",
    "# capturing images using right monochrome camera\n",
    "captureImages('right')\n",
    "\n",
    "# capturing images using left monochrome camera\n",
    "captureImages('left')\n",
    "\n",
    "# capturing images using color camera\n",
    "captureColorImages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8f9323",
   "metadata": {},
   "outputs": [],
   "source": [
    "right_images = glob.glob('images/right/*.png')\n",
    "color_images = glob.glob('images/rgb/*.png')\n",
    "left_images = glob.glob('images/left/*.png')\n",
    "\n",
    "# bruh_images = glob.glob('images/bruh/*.png')\n",
    "\n",
    "caliberate(right_images, 'right')\n",
    "caliberate(color_images, 'rgb')\n",
    "caliberate(left_images, 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa55bc2a",
   "metadata": {},
   "source": [
    "#### 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81e53a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import time\n",
    "from pathlib import Path\n",
    "import depthai as dai\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1126d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAMERA INTRINSIC MATRIX:\n",
      "[[420.0575, 0.0, 312.98673], [0.0, 394.19062, 271.42495], [0.0, 0.0, 1.0]]\n"
     ]
    }
   ],
   "source": [
    "camera_matrix = []\n",
    " \n",
    "with open('images/right/camera_matrix.txt', 'r') as f:\n",
    "    for line in f :\n",
    "        camera_matrix.append([float(num) for num in line.split(' ')])\n",
    "\n",
    "print(\"CAMERA INTRINSIC MATRIX:\")\n",
    "print(camera_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9312d2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "FX = 525\n",
    "FY = 525\n",
    "Z = 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f07bc8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_milli_to_inch(x):\n",
    "    x = x / 10\n",
    "    return x / 25.4\n",
    "image = cv.imread(\"cv object image.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0ca7dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, w, h =15,16,14,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a25b33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.142857142857142\n",
      "9.752380952380953\n",
      "17.676190476190477\n",
      "17.676190476190477\n",
      "Diameter of blue cirlce: 9.168999999999999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 54,  59,  68],\n",
       "        [ 52,  57,  66],\n",
       "        [ 51,  56,  65],\n",
       "        ...,\n",
       "        [ 44,  64,  81],\n",
       "        [ 42,  62,  79],\n",
       "        [ 40,  60,  77]],\n",
       "\n",
       "       [[ 53,  58,  67],\n",
       "        [ 52,  57,  66],\n",
       "        [ 51,  56,  65],\n",
       "        ...,\n",
       "        [ 44,  64,  81],\n",
       "        [ 43,  63,  80],\n",
       "        [ 41,  61,  78]],\n",
       "\n",
       "       [[ 53,  58,  67],\n",
       "        [ 51,  56,  65],\n",
       "        [ 51,  56,  65],\n",
       "        ...,\n",
       "        [ 44,  64,  81],\n",
       "        [ 43,  63,  80],\n",
       "        [ 42,  62,  79]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 99, 100,  98],\n",
       "        [ 98,  99,  97],\n",
       "        [ 97,  98,  96],\n",
       "        ...,\n",
       "        [ 32,  43,  47],\n",
       "        [ 33,  44,  48],\n",
       "        [ 34,  45,  49]],\n",
       "\n",
       "       [[ 99, 100,  98],\n",
       "        [ 98,  99,  97],\n",
       "        [ 97,  98,  96],\n",
       "        ...,\n",
       "        [ 33,  44,  48],\n",
       "        [ 33,  44,  48],\n",
       "        [ 33,  44,  48]],\n",
       "\n",
       "       [[100, 101,  99],\n",
       "        [ 99, 100,  98],\n",
       "        [ 97,  98,  96],\n",
       "        ...,\n",
       "        [ 34,  45,  49],\n",
       "        [ 33,  44,  48],\n",
       "        [ 32,  43,  47]]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 5)\n",
    "Image_point1x = x\n",
    "Image_point1y = y\n",
    "Image_point2x = x + w\n",
    "Image_point2y = y + h\n",
    "cv.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 5)\n",
    "cv.line(image, (Image_point1x, Image_point1y), (Image_point1x, Image_point2y), (0, 0, 255), 8)\n",
    "Real_point1x = Z * (Image_point1x / FX)\n",
    "Real_point1y = Z * (Image_point1y / FY)\n",
    "Real_point2x = Z * (Image_point2x / FX)\n",
    "Real_point2y = Z * (Image_point2x / FY)\n",
    "print(Real_point1x)\n",
    "print(Real_point1y)\n",
    "print(Real_point2x)\n",
    "print(Real_point2y)\n",
    "dist = math.sqrt((Real_point2y - Real_point1y) ** 2 + (Real_point2x - Real_point1x) ** 2)\n",
    "val = round(convert_milli_to_inch(dist*2), 5)\n",
    "print(\"Diameter of blue cirlce: {}\".format(val*100))\n",
    "cv.putText(image, str(val) + \" inches\", (Image_point1x-200, (y + y + h) // 2 + 5),cv.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c64bf24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diameter of blue circle: 9.626102476243439 cm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@40.270] global loadsave.cpp:248 findDecoder imread_('cv_object_image.jpeg'): can't open/read file: check file path/integrity\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import math\n",
    "\n",
    "def get_circle_diameter(image_path, camera_matrix_path):\n",
    "    def convert_milli_to_cm(x):\n",
    "        x = x / 10\n",
    "        return x / 25.4\n",
    "\n",
    "    # Load camera matrix\n",
    "    camera_matrix = []\n",
    "    with open(camera_matrix_path, 'r') as f:\n",
    "        for line in f:\n",
    "            camera_matrix.append([float(num) for num in line.split(' ')])\n",
    "\n",
    "    # Load image\n",
    "    image = cv.imread(image_path)\n",
    "\n",
    "    # Define points (you may need to adjust these values)\n",
    "    x, y, w, h = 15, 16, 13, 1\n",
    "    Image_point1x = x\n",
    "    Image_point1y = y\n",
    "    Image_point2x = x + w\n",
    "    Image_point2y = y + h\n",
    "\n",
    "    # Draw rectangle and line on the image\n",
    "    cv.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 5)\n",
    "    cv.line(image, (Image_point1x, Image_point1y), (Image_point1x, Image_point2y), (0, 0, 255), 8)\n",
    "\n",
    "    # Calculate real world points\n",
    "    Z = 310\n",
    "    FX = camera_matrix[0][0]\n",
    "    FY = camera_matrix[1][1]\n",
    "    Real_point1x = Z * (Image_point1x / FX)\n",
    "    Real_point1y = Z * (Image_point1y / FY)\n",
    "    Real_point2x = Z * (Image_point2x / FX)\n",
    "    Real_point2y = Z * (Image_point2y / FY)\n",
    "\n",
    "    # Calculate diameter in pixels\n",
    "    dist = math.sqrt((Real_point2y - Real_point1y) ** 2 + (Real_point2x - Real_point1x) ** 2)\n",
    "\n",
    "    return dist\n",
    "\n",
    "# Example usage:\n",
    "image_path = \"cv_object_image.jpeg\"\n",
    "camera_matrix_path = \"images/right/camera_matrix.txt\"\n",
    "diameter_cm = get_circle_diameter(image_path, camera_matrix_path)\n",
    "print(\"Diameter of blue circle: {} cm\".format(diameter_cm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7804df8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808e36d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
